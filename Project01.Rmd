---
title: "Group Project 1"
subtitle: "Biology 368/664 Bucknell University"
output: html_notebook
author: Prof. Ken Field
date: 9 Feb 2022
---

```{r Load Libraries, include=FALSE}
# Load other packages here.
if (!require("datasauRus")) install.packages("datasauRus"); library(datasauRus)
if (!require("tidyverse")) install.packages("tidyverse"); library(tidyverse)
if (!require("readbitmap")) install.packages("readbitmap"); library(readbitmap)
if (!require("imager")) install.packages("imager"); library(imager)
if (!require("cowplot")) install.packages("cowplot"); library(cowplot)
```

This project will require you to develop a tutorial to teach Bucknell students how to use R for graphing and data analysis. 

## Target Audience

Discuss with your group the target audience for the tutorial. 
Examples could be one of the new core Biology classes, another 300-level course (not 364), or a research group. 

```{r echo=FALSE}

```

## Groups

You will work with the same groups as for the Homework 2 Peer review. 

```{r}
Data <- read_csv("0besity .csv")

#PeerGroups1 %>% 
  #select(-MAJR, -CLAS, ) %>%
  #print()
```

## Grading

Each student will be expected to complete the following tasks to earn 85% of the points available for this assignment (21/25).

- Identify and obtain suitable dataset
- Use a Github repository and version control to collaborate on the project
- Spend 4-6 hours preparing, coding, and testing tutorial
  + Data exploration
  + Data visualization
  + Hypothesis testing
- Present tutorial in class
- Provide public archive suitable for sharing to students/faculty

Tutorials from previous classes can be viewed at our public github site: https://github.com/Bucknell-Biol364

Each group should use an *Acknowledgements* section to document the participation of each member and the collaboration within and between groups.

Additional credit will be awarded for providing assistance to other groups and for the development of a tutorial that goes beyond the minimal expectations listed above.


##Example of what R can do. (Sierra)

One major benefit of R is that it's all "all-in-one" program, meaning once your data is uploaded you can complete all your tasks (data wrangling, editing, visualization, statistical analyses, and professional figures) within that program.
Whereas, other programs such as Excel or JMP can complete one or two of these tasks but its much more clunky and some tasks are just not possible. 

For example: 
We have 3 figures here made on three different programs
-Excel
-JMP Pro 16
-RStudio

##Example Figure 1 using Excel
```{r}
library("jpeg")
Excel <- readJPEG("ExcelGraph.jpg",native=TRUE)
plot(0:1,0:1,type="n",ann=FALSE,axes=FALSE)
rasterImage(Excel,0,0,1,1)

#Code source: https://stackoverflow.com/questions/23861000/displaying-images-in-r-in-version-3-1-0
```
This is about as fancy as you can get for a figure using Excel and although it's not too bad, Excel can get clunky trying to work with data. Additionallly, we can't run statistacal analyses using Excel.

##Example Figure 2 using JMP pro 16
```{r}

library(imager)
JMP<-load.image("JMPproGraph.jpeg")
plot(JMP)

#Code source: https://stackoverflow.com/questions/23861000/displaying-images-in-r-in-version-3-1-0
```
Example 2 is from a statistical analysis program called JMP ("Jump"). The function pictured is called "Graph Builder" and it's a great way to visualize data before running an analysis. However, there is no way to make a nice professional figure in JMP. The figure pictured is as fancy as you can make a graph in JMP and you can't label axes or export this as an jpeg. In this case, it's kind of opposite of Excel: you can wrangle data and run analyses on it, but can't make figures.

##Example Figure 3 using RStudio
```{r}

Fig3<-ggplot(Data) +
  aes(x = Gender, y= Selection.Time) +
  geom_boxplot() +
  geom_jitter(width=.15, aes(color= Gender)) +
  ggtitle("Gender vs Reaction Time ") 
  theme_cowplot() +
  theme(axis.text.x = element_text(angle = 0, vjust = 1, hjust=0.5))
  
  Fig3


#Code source: Ashley Borseth
```
##Introduction

Introduce what is R. Why it can be useful.

What our dataset is. The measure of ability in arithmetic in obese vs non-obese individuals.

##View the data
Maybe load it into a nicely formatted table to show all the data points

Firstly, we need to familiarize ourselves with the data. The head() and tail() functions give us a snapshot of the data from the top and bottom of our data set. This is helpful to us because as of right now we aren't sure which variables we are working with!
Here we can see that our data is divided by the participants ID, Age, Gender, BMI, WS (Weight Status), and Selection Time. We will also use summary() which provides even more information about each specific variable. Things like finding the min, max, median, etc... can quickly be performed utilizing this function.
```{r}
head(Data)
tail(Data)
summary(Data)
```




##Question and Hypothesis Creation
Now that we know what the data looks like, it's time to ask some questions, create a hypothesis, and relevant predictions. 
**Question:** *Is health related to cognitive ability?*

**Hypothesis:** *Residual effects of being overweight interfere with mathematical skills*

**Prediction:** *People considered obese will take longer choosing an answer to an arithmetic problem*


##Visualize the Data!
get the data into a readable graph
perform a statistical test and conclude presentation with some sort of statement regarding the hypothesis



Lets look more into selection time, a variable that tracks the average reaction time of choosing one of three solutions for a presented math problem. Reaction times were collected within a 1400ms window (1.4 seconds). We can graph this alongside the WS category, which is weight status and is either N-O for not obese, or O for obese. 

Here we will use the ggplot package to enable us to graph and visualize the data. While this code may look overwhelming, much of it is for formatting and aesthetics. There are a few parts of this function that we would like to call your attention to:

ggplot() - an imported package allowing for better data visualization

aes() - aesthetics function, helps to set x and y axis to our specified variables from out data set. x = WS, andy y = Selection.Time. It is important to spell these exactly as they are seen in the data set. 

geom_boxplot() - This function sets the type of graph we will be using. A boxplot is a great way to visualize data as it shows the range of the data, min, max, quartiles, and median. 

geom_jitter() - This geometry function plots the individual data points on top of our boxplots which is a good idea as it can help the viewer see where the actual data points lie in relation to each other. 


```{r}
#set out graph equal to the variable firstGraph
firstGraph<-ggplot(Data) +
  aes(x = WS, y= Selection.Time) +
  geom_boxplot() +
  geom_jitter(width=.15, aes(color= WS)) +
  ggtitle("Obesity vs Reaction Time ") +
  theme_cowplot() +
  theme(axis.text.x = element_text(angle = 0, vjust = 1, hjust=0.5))
  
#call our firstGraph variable which runs the creation and outputs the graph
firstGraph


#Code source: Ashley

```


##Interpet the results

Now that we have visualized the data and can see them side by side, we should run some statistical analyses to be able to tell whether or not our prediction was correct. With one continuous variable being tested against a categorical variable, we can use a two sample t-test to determine if the two are significantly related to each other. In order to do this, we first must ensure our selection time's are distributed normally. We can use the shapiro test to test for normality, a p-value above .05 will ensure out data is distributed normally.

```{r}
#Is our data normally distributed?
shapiro.test(Data$Selection.Time)

hist(Data$Selection.Time, breaks = 8, xlab = "Selection Time (ms)", main = "Histogram of Selection Time", col = "light blue")
```
With a p-value of .9336, we know our data is definitely distributed normally and can proceed with our t-test.

```{r}

t.test(Data$Selection.Time ~ Data$WS, alternative = "two.sided", var.equal = FALSE)

```


##Significance, outcomes, etc...
With a p-value of .8558, it seems there is no correlation between obesity and selection time. This means our initial prediction was incorrect and it appears obesity may have no affect on arithmetic skills.



# Acknowledgements

